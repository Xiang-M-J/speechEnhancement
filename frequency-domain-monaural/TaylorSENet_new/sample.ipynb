{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T13:37:40.155886600Z",
     "start_time": "2024-04-10T13:37:40.129888300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "base_path = r\"D:\\\\work\\\\speechEnhancement\\\\datasets\\\\voicebank_demand\"\n",
    "audio_name = \"p232_001.wav\"\n",
    "noisy_audio_path = os.path.join(base_path, \"noisy_testset_wav\", audio_name)\n",
    "\n",
    "feat_wav, _ = sf.read(noisy_audio_path)  # (27861,)\n",
    "\n",
    "c = np.sqrt(len(feat_wav) / np.sum((feat_wav ** 2.0)))\n",
    "feat_wav = feat_wav * c   # (27861,)\n",
    "wav_len = len(feat_wav)   # wav_len = 27861\n",
    "frame_num = int(np.ceil((wav_len - 320 + 320) / 160 + 1))  # 176\n",
    "fake_wav_len = (frame_num - 1) * 160 + 320 - 320    # 28000\n",
    "left_sample = fake_wav_len - wav_len  # 139 补零\n",
    "feat_wav = torch.FloatTensor(np.concatenate((feat_wav, np.zeros([left_sample])), axis=0)) # (28000,)\n",
    "feat_x = torch.stft(feat_wav.unsqueeze(dim=0), n_fft=320, hop_length=160, win_length=320,\n",
    "                    window=torch.hann_window(320), return_complex=True).permute(0, 2, 1)\n",
    "\n",
    "#compressed\n",
    "feat_mag, feat_phase = torch.norm(feat_x, dim=1)**0.5, torch.angle(feat_x)\n",
    "feat_x_compress = torch.stack((feat_mag*torch.cos(feat_phase), feat_mag*torch.sin(feat_phase)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "feat_wav, _ = torchaudio.load(noisy_audio_path)  # (27861,)\n",
    "feat_wav = feat_wav.squeeze(0)\n",
    "c = torch.sqrt(len(feat_wav) / torch.sum((feat_wav ** 2.0)))\n",
    "feat_wav = feat_wav * c   # (27861,)\n",
    "wav_len = len(feat_wav)   # wav_len = 27861\n",
    "frame_num = int(np.ceil((wav_len - 320 + 320) / 160 + 1))  # 176\n",
    "fake_wav_len = (frame_num - 1) * 160 + 320 - 320    # 28000\n",
    "left_sample = fake_wav_len - wav_len  # 139 补零\n",
    "feat_wav = (torch.concatenate((feat_wav, torch.zeros([left_sample])), dim=0)) # (28000,)\n",
    "feat_x = torch.stft(feat_wav.unsqueeze(dim=0), n_fft=320, hop_length=160, win_length=320,\n",
    "                    window=torch.hann_window(320), return_complex=True).permute(0, 2, 1)\n",
    "\n",
    "#compressed\n",
    "feat_mag, feat_phase = torch.norm(feat_x, dim=1)**0.5, torch.angle(feat_x)\n",
    "feat_x_compress1 = torch.stack((feat_mag*torch.cos(feat_phase), feat_mag*torch.sin(feat_phase)), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T13:41:38.423014300Z",
     "start_time": "2024-04-10T13:41:38.397498900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5544)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(torch.abs(feat_x_compress1-feat_x_compress)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T13:41:41.582189600Z",
     "start_time": "2024-04-10T13:41:41.566094900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
